{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9470b88fcd1467c0",
   "metadata": {},
   "source": [
    "# PGD Attack with TensorBoard Tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19927fcb03f7c5f9",
   "metadata": {},
   "source": [
    "In this notebook, we will demonstrate how to use SecML-Torch to perform a Projected Gradient Descent (PGD) attack while tracking various metrics using TensorBoard integration.\n",
    "\n",
    "We will:\n",
    "- Load visualization utilities and dependencies\n",
    "- Load the CIFAR-10 dataset and a pre-trained robust model\n",
    "- Configure a PGD attack with multiple tracking capabilities\n",
    "- Visualize the attack results and tracked metrics using TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f60c2f1b9ecfe9d",
   "metadata": {},
   "source": [
    "#### Import dependencies and load utils functions\n",
    "\n",
    "We install/load SecMLâ€‘Torch, RobustBench and TensorBoard (to visualize metrics). If this is your first run, packages and the CIFARâ€‘10 dataset may be downloaded, which requires internet access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5847d122dc944ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr --no-stdout\n",
    "try:\n",
    "    import secmlt\n",
    "except ImportError:\n",
    "    %pip install git+https://github.com/pralab/secml-torch\n",
    "\n",
    "try:\n",
    "    import tensorboard\n",
    "except ImportError:\n",
    "    %pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a1cecb03d662493",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from pathlib import Path\n",
    "\n",
    "# SecML-Torch imports\n",
    "from secmlt.models.pytorch.base_pytorch_nn import BasePytorchClassifier\n",
    "from secmlt.metrics.classification import Accuracy\n",
    "from secmlt.adv.evasion.pgd import PGD\n",
    "from secmlt.adv.evasion.perturbation_models import LpPerturbationModels\n",
    "from secmlt.adv.backends import Backends\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "# CIFAR-10 class names\n",
    "cifar10_classes = [\n",
    "    \"plane\",\n",
    "    \"car\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\",\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251155f1fa189067",
   "metadata": {},
   "source": [
    "#### Set device and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d4b33a86bf05121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Dataset path: data/datasets/\n",
      "Logs will be saved to: data/logs/pgd_tutorial\n"
     ]
    }
   ],
   "source": [
    "# Setup device and paths\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "dataset_path = \"data/datasets/\"\n",
    "logs_path = \"data/logs/pgd_tutorial\"\n",
    "\n",
    "# Create directories if they don't exist\n",
    "Path(dataset_path).mkdir(parents=True, exist_ok=True)\n",
    "Path(logs_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"Dataset path: {dataset_path}\")\n",
    "print(f\"Logs will be saved to: {logs_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80764baad853557",
   "metadata": {},
   "source": [
    "#### Loading CIFAR-10 Dataset\n",
    "\n",
    "We'll load the CIFAR-10 dataset and use a small subset for demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "261a2f37e6143e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/datasets/cifar-10-python.tar.gz\n",
      "Extracting data/datasets/cifar-10-python.tar.gz to data/datasets/\n",
      "Loaded 20 samples from CIFAR-10 test set\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stdout\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root=dataset_path, train=False, download=True, transform=transform\n",
    ")\n",
    "\n",
    "num_samples = 20\n",
    "batch_size = num_samples // 2\n",
    "test_subset = Subset(test_dataset, list(range(num_samples)))\n",
    "test_data_loader = DataLoader(test_subset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Loaded {len(test_subset)} samples from CIFAR-10 test set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c40818c7be33a7a",
   "metadata": {},
   "source": [
    "#### Loading a Pre-trained Model\n",
    "\n",
    "We'll load a pretrained model and evaluate its robustness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1cef202d03f1cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/maurapintor/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    }
   ],
   "source": [
    "net = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar10_resnet20\", pretrained=True)\n",
    "\n",
    "net = net.to(device)\n",
    "net.eval()\n",
    "\n",
    "# Wrap the model with SecML-Torch's BasePytorchClassifier\n",
    "model = BasePytorchClassifier(net, preprocessing=transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c784ea903537f6c8",
   "metadata": {},
   "source": [
    "#### Baseline Performance Evaluation\n",
    "\n",
    "Let's evaluate the model's performance on clean images. We'll later use this information to compare performance degradation of the model, after computing adversarial examples through PGD attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e52e522dd87001ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean accuracy: 0.9500 (95.00%)\n"
     ]
    }
   ],
   "source": [
    "# Test accuracy on clean examples\n",
    "clean_accuracy = Accuracy()(model, test_data_loader)\n",
    "print(\n",
    "    f\"Clean accuracy: {clean_accuracy.item():.4f} ({clean_accuracy.item() * 100:.2f}%)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85a6059543c9dfc",
   "metadata": {},
   "source": [
    "#### Configuring PGD Attack with Tracking\n",
    "\n",
    "Here we import per-step trackers for loss, predictions, perturbation norm (Lâˆž), and gradient norm, plus the TensorBoard tracker that aggregates these signals and logs them to `logs_path` for visualization. Then we configure PGD hyperparameters and attach the tracker so that every iteration is recorded and viewable in TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d76f177c16789190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracking components imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Import tracking components\n",
    "from secmlt.trackers import (\n",
    "    LossTracker,\n",
    "    PredictionTracker,\n",
    "    PerturbationNormTracker,\n",
    "    GradientNormTracker,\n",
    "    TensorboardTracker,\n",
    ")\n",
    "\n",
    "print(\"Tracking components imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89789e8f41de3a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack configuration:\n",
      "  - Epsilon: 0.0314 (8.0/255)\n",
      "  - Number of steps: 10\n",
      "  - Step size: 0.0157 (4.0/255)\n"
     ]
    }
   ],
   "source": [
    "# Configure PGD attack parameters\n",
    "epsilon = 8 / 255     # Maximum Lâˆž perturbation\n",
    "num_steps = 10        # Number of PGD iterations\n",
    "step_size = 4 / 255   # Step size per iteration\n",
    "perturbation_model = LpPerturbationModels.LINF  # Lâˆž norm constraint\n",
    "\n",
    "print(f\"Attack configuration:\")\n",
    "print(f\"  - Epsilon: {epsilon:.4f} ({epsilon * 255:.1f}/255)\")\n",
    "print(f\"  - Number of steps: {num_steps}\")\n",
    "print(f\"  - Step size: {step_size:.4f} ({step_size * 255:.1f}/255)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e30f42795cde38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configured 4 trackers with TensorBoard logging\n",
      "TensorBoard logs cleared and will be saved to: data/logs/pgd_tutorial\n"
     ]
    }
   ],
   "source": [
    "# Set up individual trackers\n",
    "trackers = [\n",
    "    LossTracker(),\n",
    "    PredictionTracker(),\n",
    "    PerturbationNormTracker(\"linf\"),\n",
    "    GradientNormTracker(),\n",
    "]\n",
    "\n",
    "# Set up TensorBoard tracking\n",
    "tensorboard_tracker = TensorboardTracker(logs_path, trackers)\n",
    "\n",
    "print(f\"Configured {len(trackers)} trackers with TensorBoard logging\")\n",
    "print(f\"TensorBoard logs cleared and will be saved to: {logs_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac267ddb6888088b",
   "metadata": {},
   "source": [
    "#### Executing the PGD Attack with Tracking\n",
    "\n",
    "We instantiate PGD with the chosen hyperparameters and attach the TensorBoard tracker, then run it on the test dataloader. While the attack iterates, the trackers record per-step loss, predictions, perturbation Lâˆž norms, and gradient norms; these are written to `logs_path` for inspection in TensorBoard. The call returns an adversarial dataset aligned with the input batches, which we use for evaluation and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d16066d4c191584e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PGD attack configured successfully\n"
     ]
    }
   ],
   "source": [
    "# Create PGD attack with tracking\n",
    "pgd_attack = PGD(\n",
    "    perturbation_model=perturbation_model,\n",
    "    epsilon=epsilon,\n",
    "    num_steps=num_steps,\n",
    "    step_size=step_size,\n",
    "    random_start=False,\n",
    "    backend=Backends.NATIVE,\n",
    "    trackers=tensorboard_tracker,\n",
    ")\n",
    "\n",
    "print(\"PGD attack configured successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2361152967240048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing PGD attack with tracking...\n",
      "Attack completed!\n"
     ]
    }
   ],
   "source": [
    "# Execute the attack\n",
    "print(\"Executing PGD attack with tracking...\")\n",
    "pgd_native_adv_ds = pgd_attack(model, test_data_loader)\n",
    "print(\"Attack completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abca9ffbb6f41c0",
   "metadata": {},
   "source": [
    "#### Results Analysis\n",
    "\n",
    "Let's analyze the results of our PGD attack. We expect here to see performance degradation in terms of accuracy, which is the effect of the untargeted PGD attack we just run on our samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b4b44ec907eac26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Attack Results ===\n",
      "Clean accuracy:        0.9500 (95.00%)\n",
      "Adversarial accuracy:  0.0000 (0.00%)\n",
      "Attack success rate:   1.0000 (100.00%)\n"
     ]
    }
   ],
   "source": [
    "# Test accuracy on adversarial examples\n",
    "adversarial_accuracy = Accuracy()(model, pgd_native_adv_ds)\n",
    "\n",
    "print(\"=== Attack Results ===\")\n",
    "print(\n",
    "    f\"Clean accuracy:        {clean_accuracy.item():.4f} ({clean_accuracy.item() * 100:.2f}%)\"\n",
    ")\n",
    "print(\n",
    "    f\"Robust accuracy:  {adversarial_accuracy.item():.4f} ({adversarial_accuracy.item() * 100:.2f}%)\"\n",
    ")\n",
    "print(\n",
    "    f\"Attack success rate:   {1 - adversarial_accuracy.item():.4f} ({(1 - adversarial_accuracy.item()) * 100:.2f}%)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raw-tracker-explain",
   "metadata": {},
   "source": [
    "#### Accessing Raw Tracker Metrics\n",
    "\n",
    "Beyond TensorBoard, you can inspect trackers directly in code. Each tracker collects per-sample values at each PGD iteration and exposes a `get()` method that returns a tensor with shape `[num_samples, num_iterations]` (concatenated across batches). The example below uses `LossTracker` and `PredictionTracker`. We compute prediction flips, where 1 means a flip in the true label happened, which should match the display above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "raw-tracker-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw tracker summaries:\n",
      " - Final average loss (iter 9): -33.1659\n",
      " - Total prediction flips across samples/iters: 19\n",
      " - First 5 samples flips: [1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# Inspect tracker histories\n",
    "loss_hist = trackers[0].get()   # LossTracker: shape [N_samples, T_iters]\n",
    "preds_hist = trackers[1].get()  # PredictionTracker: shape [N_samples, T_iters]\n",
    "\n",
    "# Average loss over iterations\n",
    "avg_loss = loss_hist.mean(dim=0) if loss_hist.numel() > 0 else None\n",
    "\n",
    "# Prediction changes across iterations per sample\n",
    "if preds_hist.numel() > 0:\n",
    "    pred_flips_per_sample = (preds_hist[:, 1:] != preds_hist[:, :-1]).sum(dim=1)\n",
    "    total_flips = int(pred_flips_per_sample.sum().item())\n",
    "else:\n",
    "    pred_flips_per_sample, total_flips = None, 0\n",
    "\n",
    "print(\"Raw tracker summaries:\")\n",
    "if avg_loss is not None:\n",
    "    print(f\" - Final average loss (iter {avg_loss.numel()-1}): {avg_loss[-1].item():.4f}\")\n",
    "else:\n",
    "    print(\" - Loss history empty\")\n",
    "if pred_flips_per_sample is not None:\n",
    "    print(f\" - Total prediction flips across samples/iters: {total_flips}\")\n",
    "    print(f\" - First 5 samples flips: {pred_flips_per_sample[:5].tolist()}\")\n",
    "else:\n",
    "    print(\" - Prediction history empty\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1e9bbdbea66580",
   "metadata": {},
   "source": [
    "#### TensorBoard Visualization\n",
    "\n",
    "Now let's launch TensorBoard to see all the tracked metrics in detail. TensorBoard provides the most comprehensive view of the attack progression with interactive plots. We can view it inline (uncomment line below print statement), or access to the webpage on localhost. We can see how the loss, norms values progress during the attack steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2de26b9e9a2b3180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ TensorBoard: http://localhost:6007 (open in your browser if not shown inline)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Launch TensorBoard inline\n",
    "print(\n",
    "    \"ðŸš€ TensorBoard: http://localhost:6007 (open in your browser if not shown inline)\\n\"\n",
    ")\n",
    "\n",
    "# Uncomment this for inline visualization\n",
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir $logs_path --port 6007 --reload_interval 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ebc10bd13987d",
   "metadata": {},
   "source": [
    "![04-pgd-tensorboard-tracking.png](../_static/assets/tutorials/04-pgd-tensorboard-tracking.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "secmltorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
